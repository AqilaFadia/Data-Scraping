## Web Scraping with [BeautifulSoup and Requests](https://github.com/AqilaFadia/Data-Scraping/blob/main/bs4%26req/bs2.py)

This folder contains a simple web scraping project using **BeautifulSoup**, **requests**, and **urllib.parse**.
### ðŸ”§ Libraries Used
- `requests` for sending HTTP requests
- `BeautifulSoup` from `bs4` for parsing HTML
- `pandas` for saving the data into a CSV file
- `urllib.parse.urljoin` to resolve relative URLs

- ðŸ“š [Article Link](https://www.kaggle.com/datasets/aqilafadia/book-scraped)

## Web Scraping with [Scrapy](https://github.com/AqilaFadia/Data-Scraping/blob/main/bs4%26req/bs2.py)
In this post, I'll guide you through a simple web scraping project using Scrapy, one of the most powerful frameworks for web scraping in Python. Scrapy is designed for large-scale web scraping tasks and is perfect for projects that need to extract data from multiple pages or websites efficiently.

**Why Choose Scrapy?**
- Built for Speed: Scrapy is fast and can handle large amounts of data with ease.

- Complete Framework: Scrapy provides everything you need for scraping, including built-in support for crawling, parsing, and storing scraped data.

- Highly Customizable: Itâ€™s easy to customize Scrapy to suit the needs of different websites.

**Getting Started**
First, you need to install Scrapy:
```bash
pip install scrapy


- ðŸ“š [Article Link](https://www.kaggle.com/datasets/aqilafadia/book-scraped)


